---
title: "$K$NN"
author: "JACE HIGA!"
date: "02/10/2025"
format:
  html:
    theme: superhero
    mainfont: monospace
    highlight-style: github
    title-block-banner: true
    embed-resources: true
---

**Abstract:**

This is a technical blog post of **both** an HTML file *and* [.qmd file](https://raw.githubusercontent.com/cd-public/D505/refs/heads/master/hws/src/knn.qmd) hosted on GitHub pages.

# 0. Quarto Type-setting

- This document is rendered with Quarto, and configured to embed an images using the `embed-resources` option in the header.
- If you wish to use a similar header, here's is the format specification for this document:

```email
format: 
  html:
    embed-resources: true
```

# 1. Setup

```{r}
# Library and Dataset
library(tidyverse)
library(caret)
wine <- readRDS(gzcon(url("https://github.com/cd-public/D505/raw/master/dat/pinot.rds")))
```

## 2. $K$NN Concepts

> <span style="color:red;font-weight:bold">TODO</span>: *If we choose a smaller k we would just be choosing the closest neighbors, which means there will be lots of noise that has influence on the results. Choosing a larger k would mean that we take a bigger range of neighbors and would reduce the noise. However, it would make the boundaries between our classification classes less defined.*

## 3. Feature Engineering

1. Remove the taster_name column from the data.
2. Create a version of the year column that is a *factor* (instead of numeric).
3. Create dummy variables that indicate the presence of "cherry", "chocolate" and "earth" in the description.
  - Take care to handle upper and lower case characters.
4. Create 3 new features that represent the interaction between time and the cherry, chocolate and earth inidicators.
5. Remove the description column from the data.

```{r}
#Feature Engineering
wine <- wine %>%
  #select(-taster_name) %>% 
  mutate(year = as.factor(year)) %>%
  mutate(description = str_to_lower(description)) %>%
  mutate(note_cherry = str_detect(description, "cherry")) %>%
  mutate(note_chocolate = str_detect(description, "chocolate")) %>%
  mutate(note_earth = str_detect(description, "earth")) %>%
  select(-description)
```
## 4. Preprocessing

1. Preprocess the dataframe from the previous code block using BoxCox, centering and scaling of the numeric features
2. Create dummy variables for the `year` factor column

```{r}
# Preprocessing Dataframe
wine <- wine %>%
  preProcess(method = c("BoxCox", "center", "scale")) %>%
  predict(wine)
```

```{r}
library(fastDummies)

# Dummy Variables
wine <- wine %>% dummy_cols(
  select_columns = c("year"),
  remove_most_frequent_dummy = T, 
  remove_selected_columns = T)
```

## 5. Running $K$NN

1. Split the dataframe into an 80/20 training and test set
2. Use Caret to run a $K$NN model that uses your engineered features to predict province
  - use 5-fold cross validated subsampling 
  - allow Caret to try 15 different values for K
3. Display the confusion matrix on the test data


```{r}
# Splitting Data
set.seed(5)
wine_index <- createDataPartition(wine$province, p = 0.8, list = FALSE)
train <- wine[ wine_index, ]
test <- wine[-wine_index, ]
```


```{r}
# KNN Models
tr_control <- trainControl(method = "cv", number = 5)

fit <- train(province ~ .,
             data = train, 
             method = "knn",
             tuneLength = 15,
             metric = "Kappa",
             trControl = tr_control) 
fit
```

```{r}
ggplot(fit, metric = "Kappa")
```


```{r}
# Confusion Matrix
confusionMatrix(predict(fit, test),factor(test$province))
```


## 6. Kappa

How do we determine whether a Kappa value is represents a good or bad outcome?

> <span style="color:red;font-weight:bold">TODO</span>: *Generally, a good Kappa value is > 0.6.*

## 7. Improvement

How can we interpret the confusion matrix, and how can we improve in our predictions?

> <span style="color:red;font-weight:bold">TODO</span>: *The diagonals (starting from top left to bottom right) of our matrix are the values that have been correctly predicted. The others are incorrect predicted. Our kappa was 34.4% and there is an accuracy of around 60.6% with a 95% confidence intervals of 58.2% to 62.9%. One way we can try to improve our predictions is to make sure data from the different provinces are equal, meaning maybe we get 200 samples from each. This would help with consistency and could help our model more accurately classify. We could also potentially make our k smaller but then it might over fit.*